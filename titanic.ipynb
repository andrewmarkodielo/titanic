{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data imports\n",
    "train_original = pd.read_csv('C:/Users/Andrew Mark/Google Drive/Projects/Kaggle/titanic/train.csv')\n",
    "test_original = pd.read_csv('C:/Users/Andrew Mark/Google Drive/Projects/Kaggle/titanic/test.csv')\n",
    "answers = pd.read_csv('C:/Users/Andrew Mark/Google Drive/Projects/Kaggle/titanic/gender_submission.csv')\n",
    "\n",
    "train = train_original\n",
    "test = copy(test_original)\n",
    "test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleansing/pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test['PassengerId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = train.append(test, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.drop(['Name','Ticket','Cabin'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling missing values\n",
    "def fill_missing_values(df):\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0]\n",
    "    for column in list(missing.index):\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column].fillna(df[column].value_counts().index[0], inplace=True)\n",
    "        elif df[column].dtype == 'int64' or 'float64' or 'int16' or 'float16':\n",
    "            df[column].fillna(df[column].median(), inplace=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting String to Int\n",
    "def convert (df):\n",
    "    # Find the columns of object type along with their column index\n",
    "    object_cols = list(df.select_dtypes(exclude=[np.number]).columns)\n",
    "    object_cols_ind = []\n",
    "    for col in object_cols:\n",
    "        object_cols_ind.append(df.columns.get_loc(col))\n",
    "\n",
    "    # Encode the categorical columns with numbers    \n",
    "    label_enc = LabelEncoder()\n",
    "    for i in object_cols_ind:\n",
    "        df.iloc[:,i] = label_enc.fit_transform(df.iloc[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_missing_values(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convert(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bins for Fare\n",
    "f['Fare'] = pd.cut(f['Fare'], 1)\n",
    "# create bins for Age\n",
    "f['Age'] = pd.cut(f['Age'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bins of NewAge and NewFare to int\n",
    "f['Age'] = pd.get_dummies(f['Age'], columns = ['Age'], prefix=['Int'])\n",
    "\n",
    "f['Fare'] = pd.get_dummies(f['Fare'], columns = ['Fare'], prefix=['Int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# New feature\n",
    "f['Family_Size'] = f['SibSp'] + f['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = f[~f['PassengerId'].isin(ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = f[f['PassengerId'].isin(ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and labels for train and test datasets\n",
    "X_test = test_df.drop('PassengerId',1)\n",
    "y_test = answers['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = train_df.drop('PassengerId',1)\n",
    "y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_test = MinMaxScaler().fit_transform(X_test)\n",
    "X_train = MinMaxScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: \t 0.9904306220095693\n",
      "Random Forest Accuracy: \t 0.8588516746411483\n",
      "XGBClassifier Accuracy: \t 0.930622009569378\n",
      "Gradient Boosting Accuracy: \t 0.9401913875598086\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew Mark\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# training and prediction\n",
    "import xgboost as XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "lr_pred = logmodel.predict(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 100)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "model = xgb.XGBClassifier (random_state=53, n_jobs=-1, learning_rate=0.05, \n",
    "                  n_estimators=100, max_depth=4)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "gbc = GradientBoostingClassifier (random_state=53,n_estimators=100,learning_rate=0.05)\n",
    "gbc.fit(X_train,y_train)\n",
    "gbc_pred = gbc.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy: \\t\",metrics.accuracy_score(y_test, lr_pred))\n",
    "print(\"Random Forest Accuracy: \\t\", metrics.accuracy_score(y_test, rf_pred))\n",
    "print(\"XGBClassifier Accuracy: \\t\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Gradient Boosting Accuracy: \\t\", metrics.accuracy_score(y_test, gbc_pred))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         1\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n",
      "5          897         0\n",
      "6          898         1\n",
      "7          899         0\n",
      "8          900         1\n",
      "9          901         0\n"
     ]
    }
   ],
   "source": [
    "submit = pd.DataFrame({'PassengerId':test_original['PassengerId'], 'Survived':lr_pred})\n",
    "print(submit.head(10))\n",
    "submit.to_csv('C:/Users/Andrew Mark/Google Drive/Projects/Kaggle/titanic/submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
